{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Matrix_Factorisation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNULPPfBRIU3p/ZMTu/rASg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haidour18/Benchemarking-Recommender-systems-/blob/main/Matrix_Factorisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffu92iFb8KgY"
      },
      "source": [
        "!pip install kaggle\n",
        "!pip install -q keras\n",
        "!pip install numpy\n",
        "!pip install sklearn\n",
        "!pip install scipy\n",
        "!pip install surprise\n",
        "!pip install apyori\n",
        "!pip install matrix_factorization\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik1siSTNJ8ke"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from collections import defaultdict #data colector\n",
        "\n",
        "#Surprise: https://surprise.readthedocs.io/en/stable/\n",
        "import surprise\n",
        "\n",
        "from surprise.reader import Reader\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "  ##CrossValidation\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "\n",
        "  ##Matrix Factorization Algorithms\n",
        "from surprise import SVD\n",
        "from surprise import NMF\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import scipy.sparse\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "import warnings; warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pe5ubuQFpMa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMSQr2e09mEy"
      },
      "source": [
        "from google.colab import files \n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#change permissions \n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBkRRk1c9uMZ"
      },
      "source": [
        "!kaggle datasets download -d zygmunt/goodbooks-10k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01KA7TC19xYq"
      },
      "source": [
        "# DÃ©zippier le .zip obtenu\n",
        "from zipfile import ZipFile\n",
        "file_name = 'goodbooks-10k.zip'\n",
        "with ZipFile (file_name ,'r') as zip : \n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg2jwlwp91bL"
      },
      "source": [
        "cols = [\"user_id\", \"book_id\", \"rating\",]\n",
        "ratings=pd.read_csv(\"ratings.csv\")\n",
        "ratings=ratings.iloc[:3000,:]\n",
        "ratings_df = pd.DataFrame(ratings, columns = ['user_id', 'book_id', 'rating'], dtype = int)\n",
        "\n",
        "ratings_df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVkPqXpmdUJK"
      },
      "source": [
        "min_book_ratings = 2 #a movie has was rated at least \n",
        "min_user_ratings =  5 #a user rated movies at least\n",
        "\n",
        "\n",
        "ratings_flrd_df = ratings_df.groupby(\"book_id\").filter(lambda x: x['book_id'].count() >= min_book_ratings)\n",
        "ratings_flrd_df = ratings_flrd_df.groupby(\"user_id\").filter(lambda x: x['user_id'].count() >= min_user_ratings)\n",
        "\n",
        "\n",
        "\n",
        "\"{0} movies deleted; all movies are now rated at least: {1} times. Old dimensions: {2}; New dimensions: {3}\"\\\n",
        ".format(len(ratings_df.book_id.value_counts()) - len(ratings_flrd_df.book_id.value_counts())\\\n",
        "        ,min_book_ratings,ratings_df.shape, ratings_flrd_df.shape )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA9z23pzdzt9"
      },
      "source": [
        "from surprise import BaselineOnly\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "reader = Reader(rating_scale=(0.5, 5)) #line_format by default order of the fields\n",
        "data = Dataset.load_from_df(ratings_flrd_df[[\"user_id\",\t\"book_id\",\t\"rating\"]], reader=reader)\n",
        "\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "testset = trainset.build_anti_testset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yN7KeK5eTs7"
      },
      "source": [
        "def rmse_vs_factors(algorithm, data):\n",
        "  \"\"\"Returns: rmse_algorithm i.e. a list of mean RMSE of CV = 5 in cross_validate() for each  factor k in range(1, 101, 1)\n",
        "  100 values \n",
        "  Arg:  i.) algorithm = Matrix factoization algorithm, e.g SVD/NMF/PMF, ii.)  data = surprise.dataset.DatasetAutoFolds\n",
        "  \"\"\"\n",
        "  \n",
        "  rmse_algorithm = []\n",
        "  \n",
        "  for k in range(1, 101, 1):\n",
        "    algo = algorithm(n_factors = k)\n",
        "    \n",
        "    #[\"test_rmse\"] is a numpy array with min accuracy value for each testset\n",
        "    loss_fce = cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=False)[\"test_rmse\"].mean() \n",
        "    rmse_algorithm.append(loss_fce)\n",
        "  \n",
        "  return rmse_algorithm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-quf4AU0egb-"
      },
      "source": [
        "rmse_svd = rmse_vs_factors(SVD,data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0ge1Cw_e_OW"
      },
      "source": [
        "def plot_rmse(rmse, algorithm):\n",
        "  \"\"\"Returns: sub plots (2x1) of rmse against number of factors. \n",
        "     Vertical line in the second subplot identifies the arg for minimum RMSE\n",
        "    \n",
        "     Arg: i.) rmse = list of mean RMSE returned by rmse_vs_factors(), ii.) algorithm = STRING! of algo \n",
        "  \"\"\"\n",
        "  \n",
        "  plt.figure(num=None, figsize=(11, 5), dpi=80, facecolor='w', edgecolor='k')\n",
        "\n",
        "  plt.subplot(2,1,1)\n",
        "  plt.plot(rmse)\n",
        "  plt.xlim(0,100)\n",
        "  plt.title(\"{0} Performance: RMSE Against Number of Factors\".format(algorithm), size = 20 )\n",
        "  plt.ylabel(\"Mean RMSE (cv=5)\")\n",
        "\n",
        "  plt.subplot(2,1,2)\n",
        "  plt.plot(rmse)\n",
        "  plt.xlim(0,50)\n",
        "  plt.xticks(np.arange(0, 52, step=2))\n",
        "\n",
        "  plt.xlabel(\"{0}(n_factor = k)\".format(algorithm))\n",
        "  plt.ylabel(\"Mean RMSE (cv=5)\")\n",
        "  plt.axvline(np.argmin(rmse), color = \"r\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbB4hz7_fGNd"
      },
      "source": [
        "plot_rmse(rmse_svd,\"SVD\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYWf7w-kfb3q"
      },
      "source": [
        "param_grid = {'n_factors': [13,25,34,48]}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5)\n",
        "gs.fit(data)\n",
        "\n",
        "\n",
        "# best RMSE score\n",
        "print(gs.best_score['rmse'])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xcyXgoXgTFF"
      },
      "source": [
        "algo_SVD = SVD(n_factors = 11)\n",
        "algo_SVD.fit(trainset)\n",
        "\n",
        "\n",
        "# Predict ratings for all pairs (i,j) that are NOT in the training set.\n",
        "testset = trainset.build_anti_testset()\n",
        "\n",
        "predictions = algo_SVD.test(testset)\n",
        "\n",
        "# subset of the list  predictions\n",
        "predictions[0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73kdDBwBgVRY"
      },
      "source": [
        "def get_top_n(predictions, user_id, books_df, ratings_df, n = 10):\n",
        "    '''Return the top N (default) movieId for a user,.i.e. userID and history for comparisom\n",
        "    Args:\n",
        "    Returns: \n",
        "  \n",
        "    '''\n",
        "    #Peart I.: Surprise docomuntation\n",
        "    \n",
        "    #1. First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    #2. Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key = lambda x: x[1], reverse = True)\n",
        "        top_n[uid] = user_ratings[: n ]\n",
        "    \n",
        "    #Part II.: inspired by: https://beckernick.github.io/matrix-factorization-recommender/\n",
        "    \n",
        "    #3. Tells how many movies the user has already rated\n",
        "    user_data = ratings_df[ratings_df.user_id == (user_id)]\n",
        "    print('User {0} has already rated {1} movies.'.format(user_id, user_data.shape[0]))\n",
        "\n",
        "    \n",
        "    #4. Data Frame with predictions. \n",
        "    preds_df = pd.DataFrame([(id, pair[0],pair[1]) for id, row in top_n.items() for pair in row],\n",
        "                        columns=[\"user_id\" ,\"book_id\",\"rating\"])\n",
        "    \n",
        "    \n",
        "    #5. Return pred_usr, i.e. top N recommended movies with (merged) titles and genres. \n",
        "    pred_usr = preds_df[preds_df[\"user_id\"] == (user_id)].merge(books_df, how = 'left', left_on = 'book_id', right_on = 'book_id')\n",
        "            \n",
        "    #6. Return hist_usr, i.e. top N historically rated movies with (merged) titles and genres for holistic evaluation\n",
        "    hist_usr = ratings_df[ratings_df.user_id == (user_id) ].sort_values(\"rating\", ascending = False).merge\\\n",
        "    (books_df, how = 'left', left_on = 'book_id', right_on = 'book_id')\n",
        "    \n",
        "    \n",
        "    return hist_usr, pred_usr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBtcG0kujccG"
      },
      "source": [
        "books_df = pd.read_csv('books.csv')\n",
        "\n",
        "hist_SVD_1, pred_SVD_1= get_top_n(predictions, books_df = books_df, user_id = 588, ratings_df = ratings_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdKrqVnbmful"
      },
      "source": [
        "hist_SVD_1.head(15)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo5dryfonnnm"
      },
      "source": [
        "books_df.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXw54EPPmmUd"
      },
      "source": [
        "pred_SVD_1\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}