{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Benchmarking _Etat_Art.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haidour18/Benchemarking-Recommender-systems-/blob/main/Benchmarking__Etat_Art.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1xBl5LVscWe"
      },
      "source": [
        "#***Install dependecies***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTSIIDT2r_oR"
      },
      "source": [
        "!pip install kaggle\r\n",
        "!pip install -q keras\r\n",
        "!pip install numpy\r\n",
        "!pip install sklearn\r\n",
        "!pip install scipy\r\n",
        "!pip install surprise\r\n",
        "!pip install apyori"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neWDJ81Hsmvt"
      },
      "source": [
        "#***Kaggle Configuration***\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF0U1Quis-GT"
      },
      "source": [
        "from google.colab import files \r\n",
        "files.upload()\r\n",
        "\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "#change permissions \r\n",
        "!chmod 600 ~/.kaggle/kaggle.json\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNBuMt1dwbGt"
      },
      "source": [
        "!kaggle datasets download -d zygmunt/goodbooks-10k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_UA5c96xVpo"
      },
      "source": [
        "# Dézippier le .zip obtenu\r\n",
        "from zipfile import ZipFile\r\n",
        "file_name = 'goodbooks-10k.zip'\r\n",
        "with ZipFile (file_name ,'r') as zip : \r\n",
        "  zip.extractall()\r\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiqFY0ndxVdx"
      },
      "source": [
        " \r\n",
        "#***Data Preprocessing***\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttrP106CX3HB"
      },
      "source": [
        "# Importing the libraries\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import os, glob , csv\r\n",
        "import time, joblib\r\n",
        "import pandas as pd\r\n",
        "#from sklearn.model_selection import train_test_split\r\n",
        "import surprise as sp \r\n",
        "from surprise.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "from surprise import KNNBasic,accuracy\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from apyori import apriori\r\n",
        "from IPython.display import display\r\n",
        "from sklearn.metrics import mean_squared_error as mse\r\n",
        "from sklearn.metrics import mean_absolute_error as mae\r\n",
        "from sklearn.metrics.pairwise import cosine_similarity as cos\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "import warnings; warnings.simplefilter('ignore')\r\n",
        "from surprise import accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j9CRf9ZaPPg"
      },
      "source": [
        "#Eliminating unneunnecessary columns from book.csv\r\n",
        "input_file= '/content/books.csv'\r\n",
        "output_file = '/content/books_output.csv'\r\n",
        "cols_to_remove = [0,2,3,5,6,8,10,11,12,13,14,15,16,17,18,19,20,21,22] # Column indexes to be removed (starts at 0)\r\n",
        "cols_to_remove = sorted(cols_to_remove, reverse=True) # Reverse so we remove from the end first\r\n",
        "\r\n",
        "row_count = 0 # Current amount of rows processed\r\n",
        "\r\n",
        "with open(input_file, \"r\") as source:\r\n",
        "    reader = csv.reader(source)\r\n",
        "    with open(output_file, \"w\", newline='') as result:\r\n",
        "        writer = csv.writer(result)\r\n",
        "        for row in reader:\r\n",
        "            row_count += 1\r\n",
        "            print('\\r{0}'.format(row_count), end='') # Print rows processed\r\n",
        "            for col_index in cols_to_remove:\r\n",
        "                del row[col_index]\r\n",
        "            writer.writerow(row)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXV81xX8w3B3"
      },
      "source": [
        "#Avanat d'exéuter cette section de code , il faut supprimer books.csv\r\n",
        "#Jointure entre tous les fichiers csv dans un ficher csv nommé \"dataset.csv\"\r\n",
        "path = \"/content/\"\r\n",
        "\r\n",
        "all_files = glob.glob(os.path.join(path, \"*.csv\"))\r\n",
        "df_file = (pd.read_csv(f, sep=',') for f in all_files)\r\n",
        "df_merged   = pd.concat(df_file, ignore_index=True)\r\n",
        "df_merged.to_csv( \"dataset_genere.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ3P1cgZzvGY"
      },
      "source": [
        "dataset_complet=pd.read_csv(\"dataset_genere.csv\")\r\n",
        "#dataset_genere.tail(20)\r\n",
        "del dataset_complet ['Unnamed: 0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIN68vFt371C"
      },
      "source": [
        "dataset_complet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu7WC71-vRRh"
      },
      "source": [
        "#We can need it later \r\n",
        "#dataset1 =pd.read_csv('book_tags.csv')\r\n",
        "dataset2= pd.read_csv('books_output.csv')\r\n",
        "dataset3=pd.read_csv('ratings.csv')\r\n",
        "#dataset4=pd.read_csv('tags.csv')\r\n",
        "#dataset5=pd.read_csv('to_read.csv')\r\n",
        "train=pd.merge(dataset2,dataset3)\r\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS42S61R1eKm"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\r\n",
        "#train, test = train_test_split(dataset_complet, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pejCjhV53Uup"
      },
      "source": [
        "userRatings = train.pivot_table(index=['user_id'],columns=['original_title'],values='rating')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un5Qv7Dq37JU"
      },
      "source": [
        "userRatings=userRatings.dropna(thresh=10,axis=1).fillna(0)\r\n",
        "#Here we are removing the movies having less than 10 user ratings and replacing NaN values with 0.\r\n",
        "userRatings.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob0cncy04lpM"
      },
      "source": [
        "ratings=dataset3[['user_id','book_id','rating']]\r\n",
        "ratings = ratings.iloc[:20000,:]\r\n",
        "reader = sp.Reader(rating_scale=(1,5)) \r\n",
        "result_dataset1 = sp.Dataset.load_from_df(ratings, reader)\r\n",
        "train1,test1 = train_test_split(result_dataset1,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "823MEHdN07uF"
      },
      "source": [
        "user_model = sp.KNNBasic(k=40,sim_options={'name': 'pearson','user_based': True})\r\n",
        "user_model.fit(train1)\r\n",
        "preds = user_model.test(test1)\r\n",
        "accuracy.rmse(preds,verbose=True)\r\n",
        "accuracy.mae(preds,verbose=True)\r\n",
        "accuracy.mse(preds,verbose=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jGd2bfuESnG"
      },
      "source": [
        "user_model = sp.KNNBasic(k=40,sim_options={'name': 'cosine','user_based': True})\r\n",
        "user_model.fit(train1)\r\n",
        "preds = user_model.test(test1)\r\n",
        "accuracy.rmse(preds,verbose=True)\r\n",
        "accuracy.mae(preds,verbose=True)\r\n",
        "accuracy.mse(preds,verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK_Yg9W3Bj1X"
      },
      "source": [
        "item_model = sp.KNNBasic(k=40,sim_options={'name': 'pearson','user_based': False})\r\n",
        "item_model.fit(train1)\r\n",
        "preds = item_model.test(test1)\r\n",
        "accuracy.rmse(preds,verbose=True)\r\n",
        "accuracy.mae(preds,verbose=True)\r\n",
        "accuracy.mse(preds,verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Em7p40Eyzj"
      },
      "source": [
        "item_model = sp.KNNBasic(k=40,sim_options={'name': 'cosine','user_based': False})\r\n",
        "item_model.fit(train1)\r\n",
        "preds = item_model.test(test1)\r\n",
        "accuracy.rmse(preds,verbose=True)\r\n",
        "accuracy.mae(preds,verbose=True)\r\n",
        "accuracy.mse(preds,verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry8bxZTkF0Ue"
      },
      "source": [
        "**This part isn't for execution ( just a try for the moment)**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EA4ORYaDNIR"
      },
      "source": [
        "# Prevent errors with NMF\r\n",
        "dataset3['rating'] = dataset3['rating'].where(dataset3['rating'] != 0, 1e-9)\r\n",
        "\r\n",
        "testset, trainset = dataset3.loc[:180000-1 ], dataset3.iloc[180000:] \r\n",
        "print('Training set columns  :', trainset.shape)\r\n",
        "print('Validation set columns:', testset.shape)\r\n",
        "x_val, y_val = testset.drop('rating', axis=1), testset['rating'].values.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i4ZrWZ4-6lG"
      },
      "source": [
        "models = {\r\n",
        "    'SVD': {'clf': sp.SVD(random_state=0)},\r\n",
        "    'knn' : {'clf' :KNeighborsClassifier(n_neighbors=4)},\r\n",
        "    'kmeans' : {'clf' : KMeans(n_clusters=4)},\r\n",
        "    #'association_rules': {'clf' :apriori(dataset???,min_support=0.0045, min_confidence=0.2, min_lift=3, min_length=2)}\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRZYDXaPByGg"
      },
      "source": [
        "metrics_list = []\r\n",
        "\r\n",
        "def predict(row):\r\n",
        "    return bench_model.predict(row['user_id'], row['book_id']).est"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ofFvXI00w7"
      },
      "source": [
        "reader = sp.Reader(rating_scale=(0, 5))\r\n",
        "donnees= sp.Dataset.load_from_df(trainset, reader)\r\n",
        "trainsett = donnees.build_full_trainset()\r\n",
        "full_dataset = sp.Dataset.load_from_df(dataset3, reader)\r\n",
        "full_trainset = full_dataset.build_full_trainset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTzKdDzMB7Tv"
      },
      "source": [
        "for name, model in models.items():\r\n",
        "    print('Fitting', name, 'model...', end='')\r\n",
        "    \r\n",
        "    bench_model = model['clf']\r\n",
        "    time_start = time.time()\r\n",
        "    bench_model.fit(trainsett)\r\n",
        "    model['fit_time'] = time.time() - time_start\r\n",
        "\r\n",
        "    print(' completed in', model['fit_time'], 'seconds.')\r\n",
        "\r\n",
        "    print('Predicting ratings using', name, 'model...', end='')\r\n",
        "    \r\n",
        "    time_start = time.time()\r\n",
        "    model['predictions'] = x_val.apply(predict, axis=1)\r\n",
        "    model['predict_time'] = time.time() - time_start\r\n",
        "\r\n",
        "    print(' completed in', model['predict_time'], 'seconds.')\r\n",
        "\r\n",
        "    pred_mse = mse(y_val, model['predictions'])\r\n",
        "    pred_mae = mae(y_val, model['predictions'])\r\n",
        "\r\n",
        "    metrics_list.append({\r\n",
        "        'Model': name,\r\n",
        "        'Fit time (seconds)': model['fit_time'],\r\n",
        "        'Predict time (seconds)': model['predict_time'],\r\n",
        "        'MAE': pred_mae,\r\n",
        "        'MSE': pred_mse,\r\n",
        "        'RMSE': np.sqrt(pred_mse)\r\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT0B1TeNe4tf"
      },
      "source": [
        "**Content Based Recommender Systems **\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ-DC_zcfyNe"
      },
      "source": [
        "!kaggle datasets download -d rounakbanik/the-movies-dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scJszjOA1TNy"
      },
      "source": [
        "# Dézippier le .zip obtenu\n",
        "from zipfile import ZipFile\n",
        "file_name = '/content/the-movies-dataset.zip'\n",
        "with ZipFile (file_name ,'r') as zip : \n",
        "  zip.extractall()\n",
        "  print('Done')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5081Afc0dWv"
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os, glob , csv\n",
        "import time, joblib\n",
        "import pandas as pd\n",
        "#from sklearn.model_selection import train_test_split\n",
        "import surprise as sp \n",
        "from surprise.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import seaborn as sns\n",
        "\n",
        "from surprise import KNNBasic,accuracy\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from apyori import apriori\n",
        "from IPython.display import display\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics.pairwise import cosine_similarity as cos\n",
        "from sklearn.metrics import precision_score\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "from surprise import accuracy\n",
        "Movies_dataset =pd.read_csv(\"movies_metadata.csv\")\n",
        "Movies_dataset.head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "977-wtFNhExf"
      },
      "source": [
        "#Preprocessing \n",
        "\n",
        "movies_overview= Movies_dataset[['id','genres','original_title' ,'overview']]\n",
        "\n",
        "movies_overview.head()\n",
        "\n",
        "movies_overview.columns\n",
        "movies_overview.isnull().sum()\n",
        "movies_overview.dropna(subset=['overview'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olPvHUup4e_c"
      },
      "source": [
        "#Remplacer les valeurs nuls\n",
        "\n",
        "movies_overview.isnull().sum()\n",
        "movies_overview.count\n",
        "movies_overview.drop(movies_overview.tail(20000).index,inplace=True) # drop last n rows\n",
        "movies_overview.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf7C4kLpx5C6"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxyZSIbfwDcE"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "tf = TfidfVectorizer(analyzer = 'word', ngram_range = (1,2), min_df = 0, stop_words = 'english')\n",
        "tfidf_matrix = tf.fit_transform(movies_overview['overview'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "cosine_sim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okc8haj0zgeQ"
      },
      "source": [
        "overviews = movies_overview['overview']\n",
        "movies_titles = movies_overview['original_title']\n",
        "movies_genre = movies_overview['genres']\n",
        "indices = pd.Series(movies_overview.index, index = movies_overview['overview'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sSSX3Z9zpp7"
      },
      "source": [
        "#Function that gets book recommendations based on the cosine similarity score of book titles\n",
        "def movies_recommendations(overview, n):\n",
        "    idx = indices[overview]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key = lambda x:x[1], reverse = True)\n",
        "    sim_scores = sim_scores[1:n+1]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return movies_titles[movie_indices],movies_genre[movie_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rcg1zcgNzvym"
      },
      "source": [
        "#Recommend n books for a book having index 1\n",
        "movie_index = 5\n",
        "n = 2\n",
        "\n",
        "print([movie_index],movies_overview['original_title'][movie_index])\n",
        "result =movies_recommendations(movies_overview.overview[movie_index], n)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnym1FAOf3ne"
      },
      "source": [
        ""
      ]
    }
  ]
}